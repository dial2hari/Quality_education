{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7148e72c",
   "metadata": {
    "papermill": {
     "duration": 0.019986,
     "end_time": "2023-02-24T11:05:00.701718",
     "exception": false,
     "start_time": "2023-02-24T11:05:00.681732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "547b4515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/jpmml/sklearn2pmml.git\n",
      "  Cloning https://github.com/jpmml/sklearn2pmml.git to c:\\users\\86177\\appdata\\local\\temp\\pip-req-build-_1eb3ggv\n",
      "  Resolved https://github.com/jpmml/sklearn2pmml.git to commit 1c834d43ce7920b6ff900b26fda6e06820606210\n",
      "Requirement already satisfied: joblib>=0.13.0 in c:\\users\\86177\\anaconda3\\lib\\site-packages (from sklearn2pmml==0.92.0) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in c:\\users\\86177\\anaconda3\\lib\\site-packages (from sklearn2pmml==0.92.0) (0.24.2)\n",
      "Requirement already satisfied: sklearn-pandas>=0.0.10 in c:\\users\\86177\\anaconda3\\lib\\site-packages (from sklearn2pmml==0.92.0) (2.2.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\86177\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18.0->sklearn2pmml==0.92.0) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\86177\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18.0->sklearn2pmml==0.92.0) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: numpy>=1.13.3 in c:\\users\\86177\\anaconda3\\lib\\site-packages (from scikit-learn>=0.18.0->sklearn2pmml==0.92.0) (1.20.3)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\86177\\anaconda3\\lib\\site-packages (from sklearn-pandas>=0.0.10->sklearn2pmml==0.92.0) (1.3.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\86177\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->sklearn-pandas>=0.0.10->sklearn2pmml==0.92.0) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\86177\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->sklearn-pandas>=0.0.10->sklearn2pmml==0.92.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\86177\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.1.4->sklearn-pandas>=0.0.10->sklearn2pmml==0.92.0) (1.16.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/jpmml/sklearn2pmml.git 'C:\\Users\\86177\\AppData\\Local\\Temp\\pip-req-build-_1eb3ggv'\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade git+https://github.com/jpmml/sklearn2pmml.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "525c27ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sklearn2pmml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32fae418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install plotly==5.14.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e7bb684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e0aea82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:00.738057Z",
     "iopub.status.busy": "2023-02-24T11:05:00.737311Z",
     "iopub.status.idle": "2023-02-24T11:05:04.497570Z",
     "shell.execute_reply": "2023-02-24T11:05:04.496088Z"
    },
    "papermill": {
     "duration": 3.781166,
     "end_time": "2023-02-24T11:05:04.500095",
     "exception": false,
     "start_time": "2023-02-24T11:05:00.718929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\86177\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import emoji\n",
    "import string\n",
    "import nltk\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud, ImageColorGenerator, STOPWORDS\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6ca1e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525b2eb0",
   "metadata": {
    "papermill": {
     "duration": 0.019001,
     "end_time": "2023-02-24T11:05:04.535715",
     "exception": false,
     "start_time": "2023-02-24T11:05:04.516714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26ff3e10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:04.576114Z",
     "iopub.status.busy": "2023-02-24T11:05:04.575724Z",
     "iopub.status.idle": "2023-02-24T11:05:04.850704Z",
     "shell.execute_reply": "2023-02-24T11:05:04.848828Z"
    },
    "papermill": {
     "duration": 0.297384,
     "end_time": "2023-02-24T11:05:04.853530",
     "exception": false,
     "start_time": "2023-02-24T11:05:04.556146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('cyberbullying_tweets.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "190b7f46",
   "metadata": {
    "papermill": {
     "duration": 0.017539,
     "end_time": "2023-02-24T11:05:05.231347",
     "exception": false,
     "start_time": "2023-02-24T11:05:05.213808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a4a89b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:05.269256Z",
     "iopub.status.busy": "2023-02-24T11:05:05.268914Z",
     "iopub.status.idle": "2023-02-24T11:05:05.275883Z",
     "shell.execute_reply": "2023-02-24T11:05:05.274573Z"
    },
    "papermill": {
     "duration": 0.029059,
     "end_time": "2023-02-24T11:05:05.278476",
     "exception": false,
     "start_time": "2023-02-24T11:05:05.249417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.rename(columns={'tweet_text': 'text', 'cyberbullying_type': 'sentiment'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcce700",
   "metadata": {
    "papermill": {
     "duration": 0.018283,
     "end_time": "2023-02-24T11:05:05.366670",
     "exception": false,
     "start_time": "2023-02-24T11:05:05.348387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Adding Encoded column for sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adbad88b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:05.404643Z",
     "iopub.status.busy": "2023-02-24T11:05:05.404290Z",
     "iopub.status.idle": "2023-02-24T11:05:05.429566Z",
     "shell.execute_reply": "2023-02-24T11:05:05.428251Z"
    },
    "papermill": {
     "duration": 0.047189,
     "end_time": "2023-02-24T11:05:05.432010",
     "exception": false,
     "start_time": "2023-02-24T11:05:05.384821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data[\"sentiment_encoded\"] = data['sentiment'].replace({\"religion\": 1, \"age\": 2, \"ethnicity\": 3, \"gender\": 4, \"other_cyberbullying\": 5,\"not_cyberbullying\": 6})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bc3e7c",
   "metadata": {
    "papermill": {
     "duration": 0.01749,
     "end_time": "2023-02-24T11:05:05.569557",
     "exception": false,
     "start_time": "2023-02-24T11:05:05.552067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing of Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e92d57",
   "metadata": {
    "papermill": {
     "duration": 0.017292,
     "end_time": "2023-02-24T11:05:05.605407",
     "exception": false,
     "start_time": "2023-02-24T11:05:05.588115",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Function to Remove Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "105bd303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:05.643142Z",
     "iopub.status.busy": "2023-02-24T11:05:05.642799Z",
     "iopub.status.idle": "2023-02-24T11:05:05.646864Z",
     "shell.execute_reply": "2023-02-24T11:05:05.646003Z"
    },
    "papermill": {
     "duration": 0.024838,
     "end_time": "2023-02-24T11:05:05.648759",
     "exception": false,
     "start_time": "2023-02-24T11:05:05.623921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def strip_emoji(text):\n",
    "    return emoji.replace_emoji(text,replace=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402282f5",
   "metadata": {
    "papermill": {
     "duration": 0.018464,
     "end_time": "2023-02-24T11:05:05.685623",
     "exception": false,
     "start_time": "2023-02-24T11:05:05.667159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fucntion to Convert text to lowercase, remove (/r, /n  characters), URLs, non-utf characters, Numbers, punctuations,stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1af708a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:05.723216Z",
     "iopub.status.busy": "2023-02-24T11:05:05.722875Z",
     "iopub.status.idle": "2023-02-24T11:05:05.729449Z",
     "shell.execute_reply": "2023-02-24T11:05:05.728784Z"
    },
    "papermill": {
     "duration": 0.027591,
     "end_time": "2023-02-24T11:05:05.730966",
     "exception": false,
     "start_time": "2023-02-24T11:05:05.703375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def strip_all_entities(text): \n",
    "    text = text.replace('\\r', '').replace('\\n', ' ').lower()\n",
    "    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text)\n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r'', text)\n",
    "    text = re.sub(r'(.)1+', r'1', text)\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    stopchars= string.punctuation\n",
    "    table = str.maketrans('', '', stopchars)\n",
    "    text = text.translate(table)\n",
    "    text = [word for word in text.split() if word not in stop_words]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a1ea1b",
   "metadata": {
    "papermill": {
     "duration": 0.018845,
     "end_time": "2023-02-24T11:05:05.768184",
     "exception": false,
     "start_time": "2023-02-24T11:05:05.749339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Function to remove contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9104a077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:05.806921Z",
     "iopub.status.busy": "2023-02-24T11:05:05.806339Z",
     "iopub.status.idle": "2023-02-24T11:05:05.811957Z",
     "shell.execute_reply": "2023-02-24T11:05:05.811300Z"
    },
    "papermill": {
     "duration": 0.027621,
     "end_time": "2023-02-24T11:05:05.814113",
     "exception": false,
     "start_time": "2023-02-24T11:05:05.786492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decontract(text):\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea684b42",
   "metadata": {
    "papermill": {
     "duration": 0.018338,
     "end_time": "2023-02-24T11:05:05.852840",
     "exception": false,
     "start_time": "2023-02-24T11:05:05.834502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Function to Clean Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b516dad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:05.892691Z",
     "iopub.status.busy": "2023-02-24T11:05:05.891896Z",
     "iopub.status.idle": "2023-02-24T11:05:05.897220Z",
     "shell.execute_reply": "2023-02-24T11:05:05.896512Z"
    },
    "papermill": {
     "duration": 0.028297,
     "end_time": "2023-02-24T11:05:05.899498",
     "exception": false,
     "start_time": "2023-02-24T11:05:05.871201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_hashtags(tweet):\n",
    "    new_tweet = \" \".join(word.strip() for word in re.split('#(?!(?:hashtag)\\b)[\\w-]+(?=(?:\\s+#[\\w-]+)*\\s*$)', tweet))\n",
    "    new_tweet2 = \" \".join(word.strip() for word in re.split('#|_', new_tweet))\n",
    "    return new_tweet2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacb44cd",
   "metadata": {
    "papermill": {
     "duration": 0.017479,
     "end_time": "2023-02-24T11:05:05.935334",
     "exception": false,
     "start_time": "2023-02-24T11:05:05.917855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Function to Filter Special Characters such as $, &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41bc0a8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:05.972504Z",
     "iopub.status.busy": "2023-02-24T11:05:05.971937Z",
     "iopub.status.idle": "2023-02-24T11:05:05.977753Z",
     "shell.execute_reply": "2023-02-24T11:05:05.976762Z"
    },
    "papermill": {
     "duration": 0.027139,
     "end_time": "2023-02-24T11:05:05.979917",
     "exception": false,
     "start_time": "2023-02-24T11:05:05.952778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_chars(a):\n",
    "    sent = []\n",
    "    for word in a.split(' '):\n",
    "        if ('$' in word) | ('&' in word):\n",
    "            sent.append('')\n",
    "        else:\n",
    "            sent.append(word)\n",
    "    return ' '.join(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87a5a23",
   "metadata": {
    "papermill": {
     "duration": 0.017457,
     "end_time": "2023-02-24T11:05:06.016389",
     "exception": false,
     "start_time": "2023-02-24T11:05:05.998932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Function to remove mutiple sequence spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5563141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:06.054898Z",
     "iopub.status.busy": "2023-02-24T11:05:06.053777Z",
     "iopub.status.idle": "2023-02-24T11:05:06.058774Z",
     "shell.execute_reply": "2023-02-24T11:05:06.057700Z"
    },
    "papermill": {
     "duration": 0.026434,
     "end_time": "2023-02-24T11:05:06.060671",
     "exception": false,
     "start_time": "2023-02-24T11:05:06.034237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_mult_spaces(text):\n",
    "    return re.sub(\"\\s\\s+\" , \" \", text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b21e69",
   "metadata": {
    "papermill": {
     "duration": 0.017665,
     "end_time": "2023-02-24T11:05:06.096802",
     "exception": false,
     "start_time": "2023-02-24T11:05:06.079137",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Function to apply stemming to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc10a899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:06.135145Z",
     "iopub.status.busy": "2023-02-24T11:05:06.134769Z",
     "iopub.status.idle": "2023-02-24T11:05:06.140677Z",
     "shell.execute_reply": "2023-02-24T11:05:06.139012Z"
    },
    "papermill": {
     "duration": 0.028167,
     "end_time": "2023-02-24T11:05:06.143467",
     "exception": false,
     "start_time": "2023-02-24T11:05:06.115300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stemmer(text):\n",
    "    tokenized = nltk.word_tokenize(text)\n",
    "    ps = PorterStemmer()\n",
    "    return ' '.join([ps.stem(words) for words in tokenized])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bcbdd6",
   "metadata": {
    "papermill": {
     "duration": 0.018789,
     "end_time": "2023-02-24T11:05:06.181626",
     "exception": false,
     "start_time": "2023-02-24T11:05:06.162837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Function to apply lemmatization to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a900911c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:06.222497Z",
     "iopub.status.busy": "2023-02-24T11:05:06.221145Z",
     "iopub.status.idle": "2023-02-24T11:05:06.227079Z",
     "shell.execute_reply": "2023-02-24T11:05:06.225665Z"
    },
    "papermill": {
     "duration": 0.028765,
     "end_time": "2023-02-24T11:05:06.229363",
     "exception": false,
     "start_time": "2023-02-24T11:05:06.200598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    tokenized = nltk.word_tokenize(text)\n",
    "    lm = WordNetLemmatizer()\n",
    "    return ' '.join([lm.lemmatize(words) for words in tokenized])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61ee820f",
   "metadata": {
    "papermill": {
     "duration": 0.018179,
     "end_time": "2023-02-24T11:05:06.266386",
     "exception": false,
     "start_time": "2023-02-24T11:05:06.248207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Function to Preprocess the text by applying all above functions (Choose one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9755af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text): #(initial one)\n",
    "    text = strip_emoji(text)\n",
    "    text = decontract(text)\n",
    "    text = strip_all_entities(text)\n",
    "    text = clean_hashtags(text)\n",
    "    text = filter_chars(text)\n",
    "    text = remove_mult_spaces(text)\n",
    "    #text = stemmer(text)\n",
    "    #text = lemmatize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb7c2e5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:06.305586Z",
     "iopub.status.busy": "2023-02-24T11:05:06.305199Z",
     "iopub.status.idle": "2023-02-24T11:05:06.311886Z",
     "shell.execute_reply": "2023-02-24T11:05:06.310611Z"
    },
    "papermill": {
     "duration": 0.028725,
     "end_time": "2023-02-24T11:05:06.313813",
     "exception": false,
     "start_time": "2023-02-24T11:05:06.285088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess1(text): #(initial one)\n",
    "    #text = strip_emoji(text)\n",
    "    text = decontract(text)\n",
    "    text = strip_all_entities(text)\n",
    "    text = clean_hashtags(text)\n",
    "    text = filter_chars(text)\n",
    "    text = remove_mult_spaces(text)\n",
    "    #text = stemmer(text)\n",
    "    #text = lemmatize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ad184ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df1):\n",
    "    \n",
    "    df1['cleaned_text'] = df1['text'].apply(strip_emoji)\n",
    "    df1['cleaned_text'] = df1['text'].apply(decontract)\n",
    "    df1['cleaned_text'] = df1['text'].apply(strip_all_entities)\n",
    "    df1['cleaned_text'] = df1['text'].apply(clean_hashtags)\n",
    "    df1['cleaned_text'] = df1['text'].apply(filter_chars)\n",
    "    df1['cleaned_text'] = df1['text'].apply(remove_mult_spaces)\n",
    "    df1['cleaned_text'] = df1['text'].apply(stemmer)\n",
    "    df1['cleaned_text'] = df1['text'].apply(lemmatize)\n",
    "    return df1['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a0ef129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df1):\n",
    "\n",
    "    if type(df1) == type('string'):\n",
    "            df1 = strip_emoji(df1)\n",
    "            df1 = decontract(df1)\n",
    "            df1 = strip_all_entities(df1)\n",
    "            df1 = clean_hashtags(df1)\n",
    "            df1 = filter_chars(df1)\n",
    "            df1 = remove_mult_spaces(df1)\n",
    "            df1 = stemmer(df1)\n",
    "            df1 = lemmatize(df1)\n",
    "            return df1\n",
    "    else:\n",
    "            df1['cleaned_text'] = df1['text'].apply(strip_emoji)\n",
    "            df1['cleaned_text'] = df1['text'].apply(decontract)\n",
    "            df1['cleaned_text'] = df1['text'].apply(strip_all_entities)\n",
    "            df1['cleaned_text'] = df1['text'].apply(clean_hashtags)\n",
    "            df1['cleaned_text'] = df1['text'].apply(filter_chars)\n",
    "            df1['cleaned_text'] = df1['text'].apply(remove_mult_spaces)\n",
    "            df1['cleaned_text'] = df1['text'].apply(stemmer)\n",
    "            df1['cleaned_text'] = df1['text'].apply(lemmatize)\n",
    "            return df1['cleaned_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "776a299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "userinput = \"pussy pussy #$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d4827d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(\"pussy pussy #$\") == type('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad052602",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:06.352978Z",
     "iopub.status.busy": "2023-02-24T11:05:06.352667Z",
     "iopub.status.idle": "2023-02-24T11:05:41.260519Z",
     "shell.execute_reply": "2023-02-24T11:05:41.259019Z"
    },
    "papermill": {
     "duration": 34.948031,
     "end_time": "2023-02-24T11:05:41.280632",
     "exception": false,
     "start_time": "2023-02-24T11:05:06.332601",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_encoded</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>6</td>\n",
       "      <td>word katandandr food crapilici mkr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>6</td>\n",
       "      <td>aussietv white mkr theblock imacelebrityau tod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>6</td>\n",
       "      <td>classi whore red velvet cupcak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>6</td>\n",
       "      <td>meh p thank head concern anoth angri dude twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>6</td>\n",
       "      <td>isi account pretend kurdish account like islam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          sentiment  \\\n",
       "0  In other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying   \n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying   \n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying   \n",
       "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying   \n",
       "\n",
       "   sentiment_encoded                                       cleaned_text  \n",
       "0                  6                 word katandandr food crapilici mkr  \n",
       "1                  6  aussietv white mkr theblock imacelebrityau tod...  \n",
       "2                  6                     classi whore red velvet cupcak  \n",
       "3                  6  meh p thank head concern anoth angri dude twitter  \n",
       "4                  6  isi account pretend kurdish account like islam...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cleaned_text'] = data['text'].apply(preprocess)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d975f931",
   "metadata": {
    "papermill": {
     "duration": 0.018495,
     "end_time": "2023-02-24T11:05:41.355145",
     "exception": false,
     "start_time": "2023-02-24T11:05:41.336650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dealing with Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b426b6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:41.453549Z",
     "iopub.status.busy": "2023-02-24T11:05:41.453129Z",
     "iopub.status.idle": "2023-02-24T11:05:41.493013Z",
     "shell.execute_reply": "2023-02-24T11:05:41.491459Z"
    },
    "papermill": {
     "duration": 0.062652,
     "end_time": "2023-02-24T11:05:41.495580",
     "exception": false,
     "start_time": "2023-02-24T11:05:41.432928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(\"cleaned_text\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a53726c",
   "metadata": {
    "papermill": {
     "duration": 0.018609,
     "end_time": "2023-02-24T11:05:41.570434",
     "exception": false,
     "start_time": "2023-02-24T11:05:41.551825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d633b40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:41.610016Z",
     "iopub.status.busy": "2023-02-24T11:05:41.609717Z",
     "iopub.status.idle": "2023-02-24T11:05:46.586922Z",
     "shell.execute_reply": "2023-02-24T11:05:46.586115Z"
    },
    "papermill": {
     "duration": 5.000061,
     "end_time": "2023-02-24T11:05:46.589310",
     "exception": false,
     "start_time": "2023-02-24T11:05:41.589249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_encoded</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tweet_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>6</td>\n",
       "      <td>word katandandr food crapilici mkr</td>\n",
       "      <td>[word, katandandr, food, crapilici, mkr]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>6</td>\n",
       "      <td>aussietv white mkr theblock imacelebrityau tod...</td>\n",
       "      <td>[aussietv, white, mkr, theblock, imacelebritya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>6</td>\n",
       "      <td>classi whore red velvet cupcak</td>\n",
       "      <td>[classi, whore, red, velvet, cupcak]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>6</td>\n",
       "      <td>meh p thank head concern anoth angri dude twitter</td>\n",
       "      <td>[meh, p, thank, head, concern, anoth, angri, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>6</td>\n",
       "      <td>isi account pretend kurdish account like islam...</td>\n",
       "      <td>[isi, account, pretend, kurdish, account, like...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          sentiment  \\\n",
       "0  In other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying   \n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying   \n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying   \n",
       "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying   \n",
       "\n",
       "   sentiment_encoded                                       cleaned_text  \\\n",
       "0                  6                 word katandandr food crapilici mkr   \n",
       "1                  6  aussietv white mkr theblock imacelebrityau tod...   \n",
       "2                  6                     classi whore red velvet cupcak   \n",
       "3                  6  meh p thank head concern anoth angri dude twitter   \n",
       "4                  6  isi account pretend kurdish account like islam...   \n",
       "\n",
       "                                          tweet_list  \n",
       "0           [word, katandandr, food, crapilici, mkr]  \n",
       "1  [aussietv, white, mkr, theblock, imacelebritya...  \n",
       "2               [classi, whore, red, velvet, cupcak]  \n",
       "3  [meh, p, thank, head, concern, anoth, angri, d...  \n",
       "4  [isi, account, pretend, kurdish, account, like...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tweet_list'] = data['cleaned_text'].apply(word_tokenize)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78485dd",
   "metadata": {
    "papermill": {
     "duration": 0.020869,
     "end_time": "2023-02-24T11:05:46.631090",
     "exception": false,
     "start_time": "2023-02-24T11:05:46.610221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Checking length of various tweet texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9e0a514",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:46.674375Z",
     "iopub.status.busy": "2023-02-24T11:05:46.674038Z",
     "iopub.status.idle": "2023-02-24T11:05:46.704689Z",
     "shell.execute_reply": "2023-02-24T11:05:46.703540Z"
    },
    "papermill": {
     "duration": 0.054693,
     "end_time": "2023-02-24T11:05:46.707695",
     "exception": false,
     "start_time": "2023-02-24T11:05:46.653002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_len = []\n",
    "for text in data.tweet_list:\n",
    "    tweet_len = len(text)\n",
    "    text_len.append(tweet_len)\n",
    "data['text_len'] = text_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624e0381",
   "metadata": {
    "papermill": {
     "duration": 0.019491,
     "end_time": "2023-02-24T11:05:47.620367",
     "exception": false,
     "start_time": "2023-02-24T11:05:47.600876",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Removing text without words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "882ca26c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:47.661692Z",
     "iopub.status.busy": "2023-02-24T11:05:47.661323Z",
     "iopub.status.idle": "2023-02-24T11:05:47.680951Z",
     "shell.execute_reply": "2023-02-24T11:05:47.679586Z"
    },
    "papermill": {
     "duration": 0.043771,
     "end_time": "2023-02-24T11:05:47.683579",
     "exception": false,
     "start_time": "2023-02-24T11:05:47.639808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data[data['text_len']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fdd70660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:47.726075Z",
     "iopub.status.busy": "2023-02-24T11:05:47.725573Z",
     "iopub.status.idle": "2023-02-24T11:05:47.731882Z",
     "shell.execute_reply": "2023-02-24T11:05:47.730371Z"
    },
    "papermill": {
     "duration": 0.030764,
     "end_time": "2023-02-24T11:05:47.734325",
     "exception": false,
     "start_time": "2023-02-24T11:05:47.703561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44650, 6)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c791f39f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:59.283757Z",
     "iopub.status.busy": "2023-02-24T11:05:59.282973Z",
     "iopub.status.idle": "2023-02-24T11:05:59.296204Z",
     "shell.execute_reply": "2023-02-24T11:05:59.294498Z"
    },
    "papermill": {
     "duration": 0.057023,
     "end_time": "2023-02-24T11:05:59.298528",
     "exception": false,
     "start_time": "2023-02-24T11:05:59.241505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_encoded</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tweet_list</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>6</td>\n",
       "      <td>word katandandr food crapilici mkr</td>\n",
       "      <td>[word, katandandr, food, crapilici, mkr]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>6</td>\n",
       "      <td>aussietv white mkr theblock imacelebrityau tod...</td>\n",
       "      <td>[aussietv, white, mkr, theblock, imacelebritya...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>6</td>\n",
       "      <td>classi whore red velvet cupcak</td>\n",
       "      <td>[classi, whore, red, velvet, cupcak]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>6</td>\n",
       "      <td>meh p thank head concern anoth angri dude twitter</td>\n",
       "      <td>[meh, p, thank, head, concern, anoth, angri, d...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>6</td>\n",
       "      <td>isi account pretend kurdish account like islam...</td>\n",
       "      <td>[isi, account, pretend, kurdish, account, like...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text          sentiment  \\\n",
       "0  In other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1  Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying   \n",
       "2  @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying   \n",
       "3  @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying   \n",
       "4  @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying   \n",
       "\n",
       "   sentiment_encoded                                       cleaned_text  \\\n",
       "0                  6                 word katandandr food crapilici mkr   \n",
       "1                  6  aussietv white mkr theblock imacelebrityau tod...   \n",
       "2                  6                     classi whore red velvet cupcak   \n",
       "3                  6  meh p thank head concern anoth angri dude twitter   \n",
       "4                  6  isi account pretend kurdish account like islam...   \n",
       "\n",
       "                                          tweet_list  text_len  \n",
       "0           [word, katandandr, food, crapilici, mkr]         5  \n",
       "1  [aussietv, white, mkr, theblock, imacelebritya...        11  \n",
       "2               [classi, whore, red, velvet, cupcak]         5  \n",
       "3  [meh, p, thank, head, concern, anoth, angri, d...         9  \n",
       "4  [isi, account, pretend, kurdish, account, like...         8  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4fc40868",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:59.379916Z",
     "iopub.status.busy": "2023-02-24T11:05:59.379352Z",
     "iopub.status.idle": "2023-02-24T11:05:59.385065Z",
     "shell.execute_reply": "2023-02-24T11:05:59.383642Z"
    },
    "papermill": {
     "duration": 0.048944,
     "end_time": "2023-02-24T11:05:59.387306",
     "exception": false,
     "start_time": "2023-02-24T11:05:59.338362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiments = [\"religion\", \"age\", \"ethnicity\", \"gender\", \"other_cyberbullying\",\"not_cyberbullying\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d6a9f6",
   "metadata": {
    "papermill": {
     "duration": 0.038685,
     "end_time": "2023-02-24T11:05:59.466094",
     "exception": false,
     "start_time": "2023-02-24T11:05:59.427409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Splitting Data into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72b01a84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:59.550137Z",
     "iopub.status.busy": "2023-02-24T11:05:59.549081Z",
     "iopub.status.idle": "2023-02-24T11:05:59.556030Z",
     "shell.execute_reply": "2023-02-24T11:05:59.555358Z"
    },
    "papermill": {
     "duration": 0.052399,
     "end_time": "2023-02-24T11:05:59.557955",
     "exception": false,
     "start_time": "2023-02-24T11:05:59.505556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X,Y = data['cleaned_text'],data['sentiment_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43c48c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        6\n",
       "1        6\n",
       "2        6\n",
       "3        6\n",
       "4        6\n",
       "        ..\n",
       "47687    3\n",
       "47688    3\n",
       "47689    3\n",
       "47690    3\n",
       "47691    3\n",
       "Name: sentiment_encoded, Length: 44650, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "025ef933",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:59.652013Z",
     "iopub.status.busy": "2023-02-24T11:05:59.651707Z",
     "iopub.status.idle": "2023-02-24T11:05:59.677412Z",
     "shell.execute_reply": "2023-02-24T11:05:59.676133Z"
    },
    "papermill": {
     "duration": 0.070171,
     "end_time": "2023-02-24T11:05:59.681003",
     "exception": false,
     "start_time": "2023-02-24T11:05:59.610832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31255,) (31255,) (13395,) (13395,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, stratify =Y, random_state = 42)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8131081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "780      6\n",
       "17323    1\n",
       "39189    2\n",
       "19066    1\n",
       "44698    3\n",
       "        ..\n",
       "42704    3\n",
       "32187    2\n",
       "14041    4\n",
       "33441    2\n",
       "39289    2\n",
       "Name: sentiment_encoded, Length: 31255, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917ee65b",
   "metadata": {
    "papermill": {
     "duration": 0.040259,
     "end_time": "2023-02-24T11:05:59.762570",
     "exception": false,
     "start_time": "2023-02-24T11:05:59.722311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## tf-idf Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9a878ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn2pmml import PMMLPipeline, sklearn2pmml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "033e90a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cleaned_text'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX = data[['cleaned_text']]\n",
    "\n",
    "XX.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "317122b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn2pmml.feature_extraction.text import Splitter\n",
    "#vectorizer = TfidfVectorizer(analyzer = \"word\", token_pattern = None, tokenizer = Splitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e6331d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade nyoka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "185e68df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from nyoka import skl_to_pmml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "759ed915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12740    taking brown sticky joke gay people coprophili...\n",
       "32959    bullied class asked teacher could call mom emo...\n",
       "38128    definitely believe agressive strict laws punis...\n",
       "962            see daesh fleeing kobane mosule countryside\n",
       "10861    wo answer like feminists answer exposes opposi...\n",
       "                               ...                        \n",
       "40757    good luck leads silver except fuck calski dumb...\n",
       "23370    otherwise atheists support radical christians ...\n",
       "11262                  jus gonna say itagaindumb bitch mkr\n",
       "13808    niggaz call females bitches time homeboys let ...\n",
       "47458    kenyans turned bants racism color discriminati...\n",
       "Name: cleaned_text, Length: 31299, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52211d59",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13588/1102157200.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train11\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_train11\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4356\u001b[0m         \"\"\"\n\u001b[1;32m-> 4357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 \u001b[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m                 \u001b[1;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13588/2314255967.py\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(df1)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cleaned_text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrip_emoji\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cleaned_text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecontract\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cleaned_text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrip_all_entities\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cleaned_text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_hashtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "X_train11 = X_train.apply(preprocess)\n",
    "X_train11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a9c5838",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(preprocessor=preprocess1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83eb20e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod = LinearSVC(C=1, loss='hinge')\n",
    "# here you can use the key classifier, if suitable\n",
    "pipeline = Pipeline([(\"vect\", vectorizer),(\"model\", DecisionTreeClassifier()) ])\n",
    "#training the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ed47144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(preprocessor=<function preprocess1 at 0x00000236772F2160>)),\n",
       "                ('model', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "80e00823",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# exporting the model\n",
    "skl_to_pmml(pipeline,XX.columns,\"sentiment_encoded\",\"lsvc_tfidf.pmml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "acdde66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = LinearSVC(C=1, loss='hinge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "82daa6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e7c3f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "288a5161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 FunctionTransformer(func=<function preprocess at 0x00000217A7C364C0>)),\n",
       "                ('vect',\n",
       "                 TfidfVectorizer(token_pattern=None,\n",
       "                                 tokenizer=<sklearn2pmml.feature_extraction.text.Splitter object at 0x00000217A484A160>)),\n",
       "                ('model', LinearSVC(C=1, loss='hinge'))])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# here you can use the key classifier, if suitable\n",
    "pipeline = Pipeline([('prep',\n",
    "FunctionTransformer(preprocess)),(\"vect\", vectorizer),(\"model\", mod) ])\n",
    "#training the model\n",
    "pipeline.fit(data,Y)\n",
    "# exporting the model\n",
    "#skl_to_pmml(pipeline,XX.columns,\"sentiment_encoded\",\"lsvc_tfidf.pmml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "585f4665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you can use the key classifier, if suitable\n",
    "pipeline = Pipeline([(\"vect\", vectorizer),(\"model\", LogisticRegression()) ])\n",
    "#training the model\n",
    "#pipeline.fit(data,Y)\n",
    "# exporting the model\n",
    "#skl_to_pmml(pipeline,XX.columns,\"sentiment_encoded\",\"lsvc_tfidf.pmml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "92aa333a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TfidfVectorizer' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13588/4109631987.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ass hhh\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'TfidfVectorizer' object is not callable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45aef08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn2pmml import make_pmml_pipeline, sklearn2pmml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30d93b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q git+https://github.com/gmihaila/ml_things.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4784471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4c3a3d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cleaned_text'], dtype=object)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b0abdd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentiment_encoded'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39b42a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmml_pipe = make_pmml_pipeline( vectorizer, DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "df39906a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard output is empty\n",
      "Standard error:\n",
      "Exception in thread \"main\" java.lang.IllegalArgumentException: Array or list attribute 'sklearn2pmml.pipeline.PMMLPipeline.active_fields' contains an unsupported value (Python class sklearn.tree._classes.DecisionTreeClassifier)\n",
      "\tat org.jpmml.python.CastFunction.apply(CastFunction.java:47)\n",
      "\tat com.google.common.collect.Lists$TransformingRandomAccessList$1.transform(Lists.java:651)\n",
      "\tat com.google.common.collect.TransformedIterator.next(TransformedIterator.java:47)\n",
      "\tat sklearn2pmml.pipeline.PMMLPipeline.initFeatures(PMMLPipeline.java:680)\n",
      "\tat sklearn2pmml.pipeline.PMMLPipeline.encodePMML(PMMLPipeline.java:151)\n",
      "\tat com.sklearn2pmml.Main.run(Main.java:91)\n",
      "\tat com.sklearn2pmml.Main.main(Main.java:66)\n",
      "Caused by: java.lang.ClassCastException: Cannot cast sklearn.tree.TreeClassifier to java.lang.String\n",
      "\tat java.lang.Class.cast(Unknown Source)\n",
      "\tat org.jpmml.python.CastFunction.apply(CastFunction.java:45)\n",
      "\t... 6 more\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The SkLearn2PMML application has failed. The Java executable should have printed more information about the failure into its standard output and/or standard error streams",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24912/2582088850.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msklearn2pmml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpmml_pipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pmml_model11.pmml'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_repr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\sklearn2pmml\\__init__.py\u001b[0m in \u001b[0;36msklearn2pmml\u001b[1;34m(pipeline, pmml, with_repr, java_home, java_opts, user_classpath, debug)\u001b[0m\n\u001b[0;32m    284\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Standard error is empty\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mretcode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The SkLearn2PMML application has failed. The Java executable should have printed more information about the failure into its standard output and/or standard error streams\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The SkLearn2PMML application has failed. The Java executable should have printed more information about the failure into its standard output and/or standard error streams"
     ]
    }
   ],
   "source": [
    "sklearn2pmml(pmml_pipe, 'pmml_model11.pmml', with_repr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fab7a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'clf': [LogisticRegression(penalty='l2', max_iter=500)]\n",
    "    , 'clf__C': [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aa4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipeline, param_grid=param_grid, scoring='f1_macro'\n",
    "                    , cv=6, verbose=5, return_train_score=True, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d13dfc90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6,\n",
       "             estimator=Pipeline(steps=[('prep',\n",
       "                                        FunctionTransformer(func=<function preprocess at 0x00000217A7C364C0>)),\n",
       "                                       ('vect',\n",
       "                                        TfidfVectorizer(token_pattern=None,\n",
       "                                                        tokenizer=<sklearn2pmml.feature_extraction.text.Splitter object at 0x00000217A484A160>)),\n",
       "                                       ('model', LogisticRegression())]),\n",
       "             n_jobs=2,\n",
       "             param_grid={'clf': [LogisticRegression(max_iter=500)],\n",
       "                         'clf__C': [0.2, 0.4, 0.6, 0.8]},\n",
       "             return_train_score=True, scoring='f1_macro', verbose=5)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e76fa2c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The pipeline object is not an instance of PMMLPipeline. Use the 'sklearn2pmml.make_pmml_pipeline(obj)' utility function to translate a regular Scikit-Learn pipeline or estimator to a PMML pipeline",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13588/1269297146.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msklearn2pmml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pre_tfidf_log.pmml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\sklearn2pmml\\__init__.py\u001b[0m in \u001b[0;36msklearn2pmml\u001b[1;34m(pipeline, pmml, with_repr, java_home, java_opts, user_classpath, debug)\u001b[0m\n\u001b[0;32m    247\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0}: {1}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_version\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjava_version\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPMMLPipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The pipeline object is not an instance of {0}. Use the 'sklearn2pmml.make_pmml_pipeline(obj)' utility function to translate a regular Scikit-Learn pipeline or estimator to a PMML pipeline\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPMMLPipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mwith_repr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                 \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepr_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The pipeline object is not an instance of PMMLPipeline. Use the 'sklearn2pmml.make_pmml_pipeline(obj)' utility function to translate a regular Scikit-Learn pipeline or estimator to a PMML pipeline"
     ]
    }
   ],
   "source": [
    "sklearn2pmml(pipeline, \"pre_tfidf_log.pmml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b979dbf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The pipeline object is not an instance of PMMLPipeline. Use the 'sklearn2pmml.make_pmml_pipeline(obj)' utility function to translate a regular Scikit-Learn pipeline or estimator to a PMML pipeline",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13588/4191948920.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msklearn2pmml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pre_tfidf_lsvc.pmml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\sklearn2pmml\\__init__.py\u001b[0m in \u001b[0;36msklearn2pmml\u001b[1;34m(pipeline, pmml, with_repr, java_home, java_opts, user_classpath, debug)\u001b[0m\n\u001b[0;32m    247\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0}: {1}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_version\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjava_version\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPMMLPipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The pipeline object is not an instance of {0}. Use the 'sklearn2pmml.make_pmml_pipeline(obj)' utility function to translate a regular Scikit-Learn pipeline or estimator to a PMML pipeline\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPMMLPipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mwith_repr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                 \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepr_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The pipeline object is not an instance of PMMLPipeline. Use the 'sklearn2pmml.make_pmml_pipeline(obj)' utility function to translate a regular Scikit-Learn pipeline or estimator to a PMML pipeline"
     ]
    }
   ],
   "source": [
    "sklearn2pmml(pipeline, \"pre_tfidf_lsvc.pmml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn2pmml.preprocessing import ReplaceTransformer, StringNormalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "52ee9fff",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Input Text'], dtype='object')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13588/4100778476.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[1;33m(\u001b[0m\u001b[1;34m'clf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m ])\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mpipeline1122\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    339\u001b[0m         \"\"\"\n\u001b[0;32m    340\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    343\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\sklearn2pmml\\pipeline\\__init__.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m     74\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y is missing target field name(s)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPMMLPipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    301\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[1;31m# Fit or load from cache the current transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[0;32m    304\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    441\u001b[0m         \u001b[0my\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvector\u001b[0m \u001b[0mrelative\u001b[0m \u001b[0mto\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \"\"\"\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X, y, do_fit)\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;31m# strings; we don't care because pandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[1;31m# will handle either.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_col_subset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\sklearn_pandas\\dataframe_mapper.py\u001b[0m in \u001b[0;36m_get_col_subset\u001b[1;34m(self, X, cols, input_df)\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;31m# return either a DataFrame/Series or a numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    964\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[1;31m# handle the dup indexing case GH#4246\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_values_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1151\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1153\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m             \u001b[1;31m# nested tuple slicing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m         \u001b[1;31m# A collection of keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m         \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1094\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[0;32m   1095\u001b[0m             \u001b[1;33m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1372\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Input Text'], dtype='object')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mapper = DataFrameMapper([\n",
    "  ([\"Input Text\"], [StringNormalizer(\"lowercase\", trim_blanks = True), ReplaceTransformer(' +', ' '), ReplaceTransformer('[^A-Za-z]+', ' ')])\n",
    "])\n",
    "pipeline1122 = PMMLPipeline([\n",
    "  (\"mapper\", mapper),\n",
    "  ('vect', CountVectorizer(ngram_range=(1,2))), \n",
    "  ('tfidf',vectorizer), \n",
    "  ('clf', LogisticRegression(C=1))\n",
    "])\n",
    "pipeline1122.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cdc7d125",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'classes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13588/696052664.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mskl_to_pmml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mXX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"sentiment_encoded\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"pre_tfidf_lsvc.pmml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\nyoka\\skl\\skl_to_pmml.py\u001b[0m in \u001b[0;36mskl_to_pmml\u001b[1;34m(pipeline, col_names, target_name, pmml_f_name, model_name, description)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mmining_imp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpml_pp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mining_imp_values'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         PMML_kwargs = get_PMML_kwargs(model,\n\u001b[0m\u001b[0;32m     78\u001b[0m                                       \u001b[0mderived_col_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                                       \u001b[0mcol_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\86177\\anaconda3\\lib\\site-packages\\nyoka\\skl\\skl_to_pmml.py\u001b[0m in \u001b[0;36mget_PMML_kwargs\u001b[1;34m(model, derived_col_names, col_names, target_name, mining_imp_val, categoric_values, model_name)\u001b[0m\n\u001b[0;32m    162\u001b[0m                                                     model_name)}\n\u001b[0;32m    163\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0many_in\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregression_mining_model_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskl_mdl_super_cls_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m             algo_kwargs = {'RegressionModel': get_regrs_models(model,\n\u001b[0;32m    166\u001b[0m                                                            \u001b[0mderived_col_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'classes_'"
     ]
    }
   ],
   "source": [
    "skl_to_pmml(pipeline,XX.columns,\"sentiment_encoded\",\"pre_tfidf_lsvc.pmml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a52b769b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4], dtype=int64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(data1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd9d4d6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "58c2e90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tf_idf = TfidfVectorizer()\n",
    "# pipeline = PMMLPipeline([ (\"vect\", tf_idf) ])\n",
    "# #training the model\n",
    "# pipeline.fit(X_train)\n",
    "# # exporting the model\n",
    "# sklearn2pmml(pipeline, 'tfidf.pmml', with_repr = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d385a422",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:05:59.844318Z",
     "iopub.status.busy": "2023-02-24T11:05:59.843495Z",
     "iopub.status.idle": "2023-02-24T11:06:00.508763Z",
     "shell.execute_reply": "2023-02-24T11:06:00.506439Z"
    },
    "papermill": {
     "duration": 0.709931,
     "end_time": "2023-02-24T11:06:00.512950",
     "exception": false,
     "start_time": "2023-02-24T11:05:59.803019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31255, 29111)\n",
      "(13395, 29111)\n"
     ]
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer()\n",
    "X_train_tf = tf_idf.fit_transform(X_train)\n",
    "X_test_tf = tf_idf.transform(X_test)\n",
    "print(X_train_tf.shape)\n",
    "print(X_test_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2bcac9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01bfc3b",
   "metadata": {
    "papermill": {
     "duration": 0.041916,
     "end_time": "2023-02-24T11:06:10.967935",
     "exception": false,
     "start_time": "2023-02-24T11:06:10.926019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c39ea5ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:06:11.054728Z",
     "iopub.status.busy": "2023-02-24T11:06:11.052611Z",
     "iopub.status.idle": "2023-02-24T11:06:11.059527Z",
     "shell.execute_reply": "2023-02-24T11:06:11.057979Z"
    },
    "papermill": {
     "duration": 0.053053,
     "end_time": "2023-02-24T11:06:11.062033",
     "exception": false,
     "start_time": "2023-02-24T11:06:11.008980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lin_svc = LinearSVC(C=1, loss='hinge')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b8771da",
   "metadata": {
    "papermill": {
     "duration": 0.041191,
     "end_time": "2023-02-24T11:10:40.327061",
     "exception": false,
     "start_time": "2023-02-24T11:10:40.285870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "987a803d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-24T11:10:40.413234Z",
     "iopub.status.busy": "2023-02-24T11:10:40.412905Z",
     "iopub.status.idle": "2023-02-24T11:10:40.945492Z",
     "shell.execute_reply": "2023-02-24T11:10:40.944337Z"
    },
    "papermill": {
     "duration": 0.578445,
     "end_time": "2023-02-24T11:10:40.947792",
     "exception": false,
     "start_time": "2023-02-24T11:10:40.369347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "lin_svc.fit(X_train_tf,y_train)\n",
    "y_pred = lin_svc.predict(X_test_tf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "332858bb",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4f9f742b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I want hit you</td>\n",
       "      <td>want hit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             text cleaned_text\n",
       "0  I want hit you     want hit"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv('test.csv')\n",
    "data1 = data1.rename(columns={'tweet_text': 'text'})\n",
    "data1['cleaned_text'] = data1['text'].apply(preprocess)\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c4f93cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test11 = data1['cleaned_text']\n",
    "test11_tf = tf_idf.transform(test11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "001b23c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<31255x29052 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 379731 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b46f15f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1111_idf = vectorizer.transform(test11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1abf47e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    want hit\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "8e2feedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 27709)\t0.5576538838546059\n",
      "  (0, 11423)\t0.8300735785590779\n"
     ]
    }
   ],
   "source": [
    "print(test11_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "63ae8074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 27661)\t0.5576538838546059\n",
      "  (0, 11403)\t0.8300735785590779\n"
     ]
    }
   ],
   "source": [
    "print(test1111_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0d9b650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = lin_svc.predict(test11_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2eee3149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e2201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(np.asarray(y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 351.792294,
   "end_time": "2023-02-24T11:10:44.551011",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-24T11:04:52.758717",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
